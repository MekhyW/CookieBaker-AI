{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmekhyw\u001b[0m (\u001b[33mmekhyw-insper\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\felip\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "\n",
    "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\__init__.py:169: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f756de20c24c88977004a8c6e6e7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = \"float16\",\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "model_name = \"huihui-ai/Llama-3.2-3B-Instruct-abliterated\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r = 16,\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0.1,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n",
    "    task_type = \"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "def prepare_dataset(dataset):\n",
    "    def format_chat(example):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are CookieBot, a furry assistant AI created by Mekhy. Always answer in the same language as the user.\"},\n",
    "            {\"role\": \"user\", \"content\": example['query']},\n",
    "            {\"role\": \"assistant\", \"content\": example['response']}\n",
    "        ]\n",
    "        formatted_chat = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        return {\"text\": formatted_chat}\n",
    "    formatted_dataset = dataset.map(format_chat)\n",
    "    formatted_dataset = formatted_dataset['train'].remove_columns(\n",
    "        [col for col in formatted_dataset['train'].column_names if col != \"text\"]\n",
    "    )\n",
    "    return formatted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02c5b39afa945f5a0e02c917c7537c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2090473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2090473\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sfw = datasets.load_dataset(\"parquet\", data_files=\"../data/SFW_qa.parquet\")\n",
    "dataset_sfw = dataset_sfw.shuffle(seed=42)\n",
    "dataset_sfw = prepare_dataset(dataset_sfw)\n",
    "dataset_sfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb06e27f2bd54c41b6d2e0e5ccc5d805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21668668494f4b529e3b563126bff7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/899457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 899457\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_nsfw = datasets.load_dataset(\"parquet\", data_files=\"../data/NSFW_qa.parquet\")\n",
    "dataset_nsfw = dataset_nsfw.shuffle(seed=42)\n",
    "dataset_nsfw = prepare_dataset(dataset_nsfw)\n",
    "dataset_nsfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\AppData\\Roaming\\Python\\Python310\\site-packages\\trl\\trainer\\sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40615c0283614f8085942a7832094335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2090473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\AppData\\Roaming\\Python\\Python310\\site-packages\\trl\\trainer\\sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer_sfw = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_sfw,\n",
    "    peft_config=lora_config,\n",
    "    tokenizer=tokenizer,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=16,\n",
    "        warmup_steps=15,\n",
    "        max_steps=150,\n",
    "        learning_rate=3e-4,\n",
    "        fp16=True,\n",
    "        bf16=False,\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        output_dir=\"../models/SFW\",\n",
    "        gradient_checkpointing=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=150\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "torch.cuda.init()\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\felip\\OneDrive\\Documentos\\GitHub\\CookieBaker-AI\\training\\notebooks\\wandb\\run-20241226_210612-p3rnm3qc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mekhyw-insper/Fine-tune%20Llama-3.2-3B-Instruct-abliterated%20on%20CookieBaker%20SFW%20Dataset/runs/p3rnm3qc' target=\"_blank\">pretty-dragon-1</a></strong> to <a href='https://wandb.ai/mekhyw-insper/Fine-tune%20Llama-3.2-3B-Instruct-abliterated%20on%20CookieBaker%20SFW%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mekhyw-insper/Fine-tune%20Llama-3.2-3B-Instruct-abliterated%20on%20CookieBaker%20SFW%20Dataset' target=\"_blank\">https://wandb.ai/mekhyw-insper/Fine-tune%20Llama-3.2-3B-Instruct-abliterated%20on%20CookieBaker%20SFW%20Dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mekhyw-insper/Fine-tune%20Llama-3.2-3B-Instruct-abliterated%20on%20CookieBaker%20SFW%20Dataset/runs/p3rnm3qc' target=\"_blank\">https://wandb.ai/mekhyw-insper/Fine-tune%20Llama-3.2-3B-Instruct-abliterated%20on%20CookieBaker%20SFW%20Dataset/runs/p3rnm3qc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d514dc825374eaf948b54f59b8de524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "C:\\Users\\felip\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.172, 'grad_norm': 2.6533937454223633, 'learning_rate': 1.9999999999999998e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m run \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39minit(\n\u001b[0;32m      2\u001b[0m     project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFine-tune Llama-3.2-3B-Instruct-abliterated on CookieBaker SFW Dataset\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      3\u001b[0m     job_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      4\u001b[0m     anonymous\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrainer_sfw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m trainer_sfw\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/SFW/checkpoint-150\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2479\u001b[0m )\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2487\u001b[0m ):\n\u001b[0;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer.py:3612\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3612\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3613\u001b[0m     \u001b[38;5;66;03m# Finally we need to normalize the loss for reporting\u001b[39;00m\n\u001b[0;32m   3614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\accelerate\\accelerator.py:2237\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2238\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[0;32m   2239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project='Fine-tune Llama-3.2-3B-Instruct-abliterated on CookieBaker SFW Dataset', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")\n",
    "\n",
    "trainer_sfw.train()\n",
    "trainer_sfw.model.save_pretrained(\"../models/SFW/checkpoint-150\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model_sfw = trainer_sfw.model.merge_and_unload()\n",
    "merged_model_sfw.save_pretrained(\"../models/SFW_merged\")\n",
    "tokenizer.save_pretrained(\"../models/SFW_merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940ac91e38374cccb881385ef8109edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/899457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "del trainer_sfw\n",
    "\n",
    "trainer_nsfw = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_nsfw,\n",
    "    peft_config=lora_config,\n",
    "    tokenizer=tokenizer,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=16,\n",
    "        warmup_steps=15,\n",
    "        max_steps=150,\n",
    "        learning_rate=1e-5,\n",
    "        fp16=True,\n",
    "        bf16=False,\n",
    "        logging_steps=1,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        output_dir=\"../models/NSFW\",\n",
    "        gradient_checkpointing=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=150\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f136b7da2dce4dabbe27386c2550767e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\felip\\OneDrive\\Documentos\\GitHub\\CookieBaker-AI\\training\\notebooks\\wandb\\run-20241129_152318-5c5f7111</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mekhyw-insper/Fine-tune%20Gemma-2-2b-it-abliterated%20on%20CookieBaker%20NSFW%20Dataset/runs/5c5f7111' target=\"_blank\">polar-snow-3</a></strong> to <a href='https://wandb.ai/mekhyw-insper/Fine-tune%20Gemma-2-2b-it-abliterated%20on%20CookieBaker%20NSFW%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mekhyw-insper/Fine-tune%20Gemma-2-2b-it-abliterated%20on%20CookieBaker%20NSFW%20Dataset' target=\"_blank\">https://wandb.ai/mekhyw-insper/Fine-tune%20Gemma-2-2b-it-abliterated%20on%20CookieBaker%20NSFW%20Dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mekhyw-insper/Fine-tune%20Gemma-2-2b-it-abliterated%20on%20CookieBaker%20NSFW%20Dataset/runs/5c5f7111' target=\"_blank\">https://wandb.ai/mekhyw-insper/Fine-tune%20Gemma-2-2b-it-abliterated%20on%20CookieBaker%20NSFW%20Dataset/runs/5c5f7111</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55d7f15ce4c473cbb9b54d883390d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "C:\\Users\\felip\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.0472, 'grad_norm': 5.640249252319336, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.0}\n",
      "{'loss': 9.9103, 'grad_norm': 5.3359575271606445, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.0}\n",
      "{'loss': 9.91, 'grad_norm': 5.649725437164307, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}\n",
      "{'loss': 10.6934, 'grad_norm': 6.252277374267578, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.0}\n",
      "{'loss': 9.1249, 'grad_norm': 4.859716892242432, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.0}\n",
      "{'loss': 10.6582, 'grad_norm': 6.081592082977295, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 10.8661, 'grad_norm': 6.438713073730469, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.0}\n",
      "{'loss': 10.2628, 'grad_norm': 5.9638190269470215, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.0}\n",
      "{'loss': 9.8225, 'grad_norm': 5.639041900634766, 'learning_rate': 6e-06, 'epoch': 0.0}\n",
      "{'loss': 7.4904, 'grad_norm': 3.9086406230926514, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.0}\n",
      "{'loss': 11.0059, 'grad_norm': 6.750884532928467, 'learning_rate': 7.333333333333333e-06, 'epoch': 0.0}\n",
      "{'loss': 10.2236, 'grad_norm': 6.078712463378906, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 10.4073, 'grad_norm': 6.4061970710754395, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.0}\n",
      "{'loss': 9.2323, 'grad_norm': 5.147252082824707, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.0}\n",
      "{'loss': 9.8267, 'grad_norm': 5.7242584228515625, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 8.9989, 'grad_norm': 5.489227771759033, 'learning_rate': 9.925925925925927e-06, 'epoch': 0.0}\n",
      "{'loss': 10.0606, 'grad_norm': 6.177982330322266, 'learning_rate': 9.851851851851852e-06, 'epoch': 0.0}\n",
      "{'loss': 10.0819, 'grad_norm': 6.494633197784424, 'learning_rate': 9.777777777777779e-06, 'epoch': 0.0}\n",
      "{'loss': 10.0367, 'grad_norm': 6.441848278045654, 'learning_rate': 9.703703703703703e-06, 'epoch': 0.0}\n",
      "{'loss': 6.4789, 'grad_norm': 3.7021360397338867, 'learning_rate': 9.62962962962963e-06, 'epoch': 0.0}\n",
      "{'loss': 10.2468, 'grad_norm': 7.147369861602783, 'learning_rate': 9.555555555555556e-06, 'epoch': 0.0}\n",
      "{'loss': 8.9964, 'grad_norm': 6.021342754364014, 'learning_rate': 9.481481481481483e-06, 'epoch': 0.0}\n",
      "{'loss': 10.2916, 'grad_norm': 7.185448169708252, 'learning_rate': 9.407407407407408e-06, 'epoch': 0.0}\n",
      "{'loss': 9.2134, 'grad_norm': 6.228518962860107, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.0}\n",
      "{'loss': 8.5277, 'grad_norm': 5.725605010986328, 'learning_rate': 9.25925925925926e-06, 'epoch': 0.0}\n",
      "{'loss': 9.6589, 'grad_norm': 6.788937568664551, 'learning_rate': 9.185185185185186e-06, 'epoch': 0.0}\n",
      "{'loss': 8.8419, 'grad_norm': 6.104850769042969, 'learning_rate': 9.111111111111112e-06, 'epoch': 0.0}\n",
      "{'loss': 8.7347, 'grad_norm': 5.9596099853515625, 'learning_rate': 9.037037037037037e-06, 'epoch': 0.0}\n",
      "{'loss': 9.059, 'grad_norm': 6.743227958679199, 'learning_rate': 8.962962962962963e-06, 'epoch': 0.0}\n",
      "{'loss': 9.5029, 'grad_norm': 7.28195858001709, 'learning_rate': 8.888888888888888e-06, 'epoch': 0.0}\n",
      "{'loss': 7.4138, 'grad_norm': 5.00845193862915, 'learning_rate': 8.814814814814817e-06, 'epoch': 0.0}\n",
      "{'loss': 9.1077, 'grad_norm': 6.990591526031494, 'learning_rate': 8.740740740740741e-06, 'epoch': 0.0}\n",
      "{'loss': 8.2882, 'grad_norm': 6.185837268829346, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.0}\n",
      "{'loss': 8.3422, 'grad_norm': 6.250503063201904, 'learning_rate': 8.592592592592593e-06, 'epoch': 0.0}\n",
      "{'loss': 9.4368, 'grad_norm': 8.091031074523926, 'learning_rate': 8.518518518518519e-06, 'epoch': 0.0}\n",
      "{'loss': 7.6709, 'grad_norm': 5.61014461517334, 'learning_rate': 8.444444444444446e-06, 'epoch': 0.0}\n",
      "{'loss': 12.5676, 'grad_norm': nan, 'learning_rate': 8.444444444444446e-06, 'epoch': 0.0}\n",
      "{'loss': 8.4588, 'grad_norm': 6.642368793487549, 'learning_rate': 8.37037037037037e-06, 'epoch': 0.0}\n",
      "{'loss': 8.6901, 'grad_norm': 6.8221330642700195, 'learning_rate': 8.296296296296297e-06, 'epoch': 0.0}\n",
      "{'loss': 7.9532, 'grad_norm': 5.975425720214844, 'learning_rate': 8.222222222222222e-06, 'epoch': 0.0}\n",
      "{'loss': 8.5919, 'grad_norm': 7.5021562576293945, 'learning_rate': 8.148148148148148e-06, 'epoch': 0.0}\n",
      "{'loss': 7.6821, 'grad_norm': 5.613699913024902, 'learning_rate': 8.074074074074075e-06, 'epoch': 0.0}\n",
      "{'loss': 8.5184, 'grad_norm': 6.851784706115723, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 8.5835, 'grad_norm': 6.816142559051514, 'learning_rate': 7.925925925925926e-06, 'epoch': 0.0}\n",
      "{'loss': 8.5867, 'grad_norm': 7.114953517913818, 'learning_rate': 7.851851851851853e-06, 'epoch': 0.0}\n",
      "{'loss': 8.4051, 'grad_norm': 7.23154878616333, 'learning_rate': 7.77777777777778e-06, 'epoch': 0.0}\n",
      "{'loss': 7.625, 'grad_norm': 6.267953872680664, 'learning_rate': 7.703703703703704e-06, 'epoch': 0.0}\n",
      "{'loss': 7.9621, 'grad_norm': 6.764136791229248, 'learning_rate': 7.62962962962963e-06, 'epoch': 0.0}\n",
      "{'loss': 8.0419, 'grad_norm': 7.266951560974121, 'learning_rate': 7.555555555555556e-06, 'epoch': 0.0}\n",
      "{'loss': 7.8596, 'grad_norm': 6.200250625610352, 'learning_rate': 7.481481481481482e-06, 'epoch': 0.0}\n",
      "{'loss': 8.2619, 'grad_norm': 7.388625621795654, 'learning_rate': 7.4074074074074075e-06, 'epoch': 0.0}\n",
      "{'loss': 7.5227, 'grad_norm': 6.277222156524658, 'learning_rate': 7.333333333333333e-06, 'epoch': 0.0}\n",
      "{'loss': 7.7018, 'grad_norm': 6.761936664581299, 'learning_rate': 7.2592592592592605e-06, 'epoch': 0.0}\n",
      "{'loss': 7.6614, 'grad_norm': 7.020855903625488, 'learning_rate': 7.185185185185186e-06, 'epoch': 0.0}\n",
      "{'loss': 7.3927, 'grad_norm': 6.2798614501953125, 'learning_rate': 7.111111111111112e-06, 'epoch': 0.0}\n",
      "{'loss': 7.5971, 'grad_norm': 6.7986226081848145, 'learning_rate': 7.0370370370370375e-06, 'epoch': 0.0}\n",
      "{'loss': 7.2777, 'grad_norm': 6.312342166900635, 'learning_rate': 6.962962962962964e-06, 'epoch': 0.0}\n",
      "{'loss': 6.9799, 'grad_norm': 5.679391860961914, 'learning_rate': 6.88888888888889e-06, 'epoch': 0.0}\n",
      "{'loss': 7.7762, 'grad_norm': 6.8848981857299805, 'learning_rate': 6.814814814814815e-06, 'epoch': 0.0}\n",
      "{'loss': 6.9183, 'grad_norm': 5.782047748565674, 'learning_rate': 6.740740740740741e-06, 'epoch': 0.0}\n",
      "{'loss': 7.4531, 'grad_norm': 6.658273220062256, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.0}\n",
      "{'loss': 6.8659, 'grad_norm': 5.420024394989014, 'learning_rate': 6.592592592592592e-06, 'epoch': 0.0}\n",
      "{'loss': 7.024, 'grad_norm': 6.001608848571777, 'learning_rate': 6.51851851851852e-06, 'epoch': 0.0}\n",
      "{'loss': 7.1002, 'grad_norm': 5.684037208557129, 'learning_rate': 6.444444444444445e-06, 'epoch': 0.0}\n",
      "{'loss': 7.556, 'grad_norm': 7.070574760437012, 'learning_rate': 6.370370370370371e-06, 'epoch': 0.0}\n",
      "{'loss': 7.1539, 'grad_norm': 5.825118064880371, 'learning_rate': 6.296296296296297e-06, 'epoch': 0.0}\n",
      "{'loss': 7.1168, 'grad_norm': 5.640423774719238, 'learning_rate': 6.222222222222223e-06, 'epoch': 0.0}\n",
      "{'loss': 6.8565, 'grad_norm': 5.52203369140625, 'learning_rate': 6.148148148148149e-06, 'epoch': 0.0}\n",
      "{'loss': 7.3187, 'grad_norm': 6.662032127380371, 'learning_rate': 6.0740740740740745e-06, 'epoch': 0.0}\n",
      "{'loss': 7.0256, 'grad_norm': 5.759033203125, 'learning_rate': 6e-06, 'epoch': 0.0}\n",
      "{'loss': 6.93, 'grad_norm': 5.89305305480957, 'learning_rate': 5.925925925925926e-06, 'epoch': 0.0}\n",
      "{'loss': 6.4715, 'grad_norm': 4.813185214996338, 'learning_rate': 5.8518518518518515e-06, 'epoch': 0.0}\n",
      "{'loss': 6.616, 'grad_norm': 4.945833683013916, 'learning_rate': 5.777777777777778e-06, 'epoch': 0.0}\n",
      "{'loss': 6.8983, 'grad_norm': 5.671093463897705, 'learning_rate': 5.7037037037037045e-06, 'epoch': 0.0}\n",
      "{'loss': 6.4838, 'grad_norm': 5.342313289642334, 'learning_rate': 5.62962962962963e-06, 'epoch': 0.0}\n",
      "{'loss': 6.4998, 'grad_norm': 5.441424369812012, 'learning_rate': 5.555555555555557e-06, 'epoch': 0.0}\n",
      "{'loss': 6.4255, 'grad_norm': 5.718043327331543, 'learning_rate': 5.481481481481482e-06, 'epoch': 0.0}\n",
      "{'loss': 7.0655, 'grad_norm': 6.341522693634033, 'learning_rate': 5.407407407407408e-06, 'epoch': 0.0}\n",
      "{'loss': 6.7047, 'grad_norm': 5.257484436035156, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.0}\n",
      "{'loss': 5.7353, 'grad_norm': 3.9998867511749268, 'learning_rate': 5.259259259259259e-06, 'epoch': 0.0}\n",
      "{'loss': 6.6304, 'grad_norm': 4.638749122619629, 'learning_rate': 5.185185185185185e-06, 'epoch': 0.0}\n",
      "{'loss': 6.6467, 'grad_norm': 4.8028883934021, 'learning_rate': 5.1111111111111115e-06, 'epoch': 0.0}\n",
      "{'loss': 6.1439, 'grad_norm': 4.700263977050781, 'learning_rate': 5.037037037037037e-06, 'epoch': 0.0}\n",
      "{'loss': 6.4985, 'grad_norm': 4.846108436584473, 'learning_rate': 4.962962962962964e-06, 'epoch': 0.0}\n",
      "{'loss': 6.2954, 'grad_norm': 4.647286415100098, 'learning_rate': 4.888888888888889e-06, 'epoch': 0.0}\n",
      "{'loss': 6.2902, 'grad_norm': 4.407411098480225, 'learning_rate': 4.814814814814815e-06, 'epoch': 0.0}\n",
      "{'loss': 6.4288, 'grad_norm': 4.418837070465088, 'learning_rate': 4.7407407407407415e-06, 'epoch': 0.0}\n",
      "{'loss': 6.2996, 'grad_norm': 4.373396396636963, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.0}\n",
      "{'loss': 6.2157, 'grad_norm': 4.256215572357178, 'learning_rate': 4.592592592592593e-06, 'epoch': 0.0}\n",
      "{'loss': 6.5909, 'grad_norm': 4.704657077789307, 'learning_rate': 4.5185185185185185e-06, 'epoch': 0.0}\n",
      "{'loss': 6.3897, 'grad_norm': 4.423285484313965, 'learning_rate': 4.444444444444444e-06, 'epoch': 0.0}\n",
      "{'loss': 6.0956, 'grad_norm': 4.194725036621094, 'learning_rate': 4.370370370370371e-06, 'epoch': 0.0}\n",
      "{'loss': 6.2963, 'grad_norm': 4.5506205558776855, 'learning_rate': 4.296296296296296e-06, 'epoch': 0.0}\n",
      "{'loss': 6.1138, 'grad_norm': 3.7785236835479736, 'learning_rate': 4.222222222222223e-06, 'epoch': 0.0}\n",
      "{'loss': 6.2944, 'grad_norm': 4.52910041809082, 'learning_rate': 4.1481481481481485e-06, 'epoch': 0.0}\n",
      "{'loss': 6.1162, 'grad_norm': 4.410584926605225, 'learning_rate': 4.074074074074074e-06, 'epoch': 0.0}\n",
      "{'loss': 6.1862, 'grad_norm': 4.011416912078857, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 6.0052, 'grad_norm': 4.050644397735596, 'learning_rate': 3.925925925925926e-06, 'epoch': 0.0}\n",
      "{'loss': 6.4206, 'grad_norm': 4.878848552703857, 'learning_rate': 3.851851851851852e-06, 'epoch': 0.0}\n",
      "{'loss': 6.0681, 'grad_norm': 4.036311149597168, 'learning_rate': 3.777777777777778e-06, 'epoch': 0.0}\n",
      "{'loss': 6.0232, 'grad_norm': 3.8263726234436035, 'learning_rate': 3.7037037037037037e-06, 'epoch': 0.0}\n",
      "{'loss': 6.1646, 'grad_norm': 4.464507102966309, 'learning_rate': 3.6296296296296302e-06, 'epoch': 0.0}\n",
      "{'loss': 6.1284, 'grad_norm': 3.8286845684051514, 'learning_rate': 3.555555555555556e-06, 'epoch': 0.0}\n",
      "{'loss': 6.1011, 'grad_norm': 3.978696823120117, 'learning_rate': 3.481481481481482e-06, 'epoch': 0.0}\n",
      "{'loss': 6.0629, 'grad_norm': 3.471497058868408, 'learning_rate': 3.4074074074074077e-06, 'epoch': 0.0}\n",
      "{'loss': 6.1376, 'grad_norm': 3.780287742614746, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.0}\n",
      "{'loss': 6.1086, 'grad_norm': 3.6561033725738525, 'learning_rate': 3.25925925925926e-06, 'epoch': 0.0}\n",
      "{'loss': 5.7888, 'grad_norm': 3.619263172149658, 'learning_rate': 3.1851851851851855e-06, 'epoch': 0.0}\n",
      "{'loss': 6.0841, 'grad_norm': 3.8255085945129395, 'learning_rate': 3.1111111111111116e-06, 'epoch': 0.0}\n",
      "{'loss': 6.1441, 'grad_norm': 4.0171732902526855, 'learning_rate': 3.0370370370370372e-06, 'epoch': 0.0}\n",
      "{'loss': 6.0358, 'grad_norm': 3.8204185962677, 'learning_rate': 2.962962962962963e-06, 'epoch': 0.0}\n",
      "{'loss': 5.0876, 'grad_norm': 2.985891580581665, 'learning_rate': 2.888888888888889e-06, 'epoch': 0.0}\n",
      "{'loss': 6.3169, 'grad_norm': 4.050252437591553, 'learning_rate': 2.814814814814815e-06, 'epoch': 0.0}\n",
      "{'loss': 6.0414, 'grad_norm': 3.5812759399414062, 'learning_rate': 2.740740740740741e-06, 'epoch': 0.0}\n",
      "{'loss': 5.717, 'grad_norm': 3.775737762451172, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.0}\n",
      "{'loss': 5.7405, 'grad_norm': 3.6585705280303955, 'learning_rate': 2.5925925925925925e-06, 'epoch': 0.0}\n",
      "{'loss': 5.8802, 'grad_norm': 3.8140106201171875, 'learning_rate': 2.5185185185185186e-06, 'epoch': 0.0}\n",
      "{'loss': 5.7119, 'grad_norm': 3.5611367225646973, 'learning_rate': 2.4444444444444447e-06, 'epoch': 0.0}\n",
      "{'loss': 5.7489, 'grad_norm': 3.3441193103790283, 'learning_rate': 2.3703703703703707e-06, 'epoch': 0.0}\n",
      "{'loss': 5.7368, 'grad_norm': 3.6451096534729004, 'learning_rate': 2.2962962962962964e-06, 'epoch': 0.0}\n",
      "{'loss': 5.9407, 'grad_norm': 3.5076589584350586, 'learning_rate': 2.222222222222222e-06, 'epoch': 0.0}\n",
      "{'loss': 5.8608, 'grad_norm': 3.538865804672241, 'learning_rate': 2.148148148148148e-06, 'epoch': 0.0}\n",
      "{'loss': 6.0291, 'grad_norm': 3.9734456539154053, 'learning_rate': 2.0740740740740742e-06, 'epoch': 0.0}\n",
      "{'loss': 6.0368, 'grad_norm': 4.064731597900391, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}\n",
      "{'loss': 5.9829, 'grad_norm': 4.28141975402832, 'learning_rate': 1.925925925925926e-06, 'epoch': 0.0}\n",
      "{'loss': 5.9572, 'grad_norm': 3.544639825820923, 'learning_rate': 1.8518518518518519e-06, 'epoch': 0.0}\n",
      "{'loss': 6.0588, 'grad_norm': 3.8584654331207275, 'learning_rate': 1.777777777777778e-06, 'epoch': 0.0}\n",
      "{'loss': 5.947, 'grad_norm': 4.332820892333984, 'learning_rate': 1.7037037037037038e-06, 'epoch': 0.0}\n",
      "{'loss': 5.8705, 'grad_norm': 3.6252541542053223, 'learning_rate': 1.62962962962963e-06, 'epoch': 0.0}\n",
      "{'loss': 5.5231, 'grad_norm': 2.829103469848633, 'learning_rate': 1.5555555555555558e-06, 'epoch': 0.0}\n",
      "{'loss': 5.8803, 'grad_norm': 3.8421010971069336, 'learning_rate': 1.4814814814814815e-06, 'epoch': 0.0}\n",
      "{'loss': 5.5639, 'grad_norm': 3.905120372772217, 'learning_rate': 1.4074074074074075e-06, 'epoch': 0.0}\n",
      "{'loss': 5.4512, 'grad_norm': 2.924635648727417, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.0}\n",
      "{'loss': 5.6486, 'grad_norm': 4.225833892822266, 'learning_rate': 1.2592592592592593e-06, 'epoch': 0.0}\n",
      "{'loss': 5.6028, 'grad_norm': 3.1741812229156494, 'learning_rate': 1.1851851851851854e-06, 'epoch': 0.0}\n",
      "{'loss': 5.348, 'grad_norm': 2.706515312194824, 'learning_rate': 1.111111111111111e-06, 'epoch': 0.0}\n",
      "{'loss': 5.9326, 'grad_norm': 3.2014267444610596, 'learning_rate': 1.0370370370370371e-06, 'epoch': 0.0}\n",
      "{'loss': 5.6877, 'grad_norm': 3.8718209266662598, 'learning_rate': 9.62962962962963e-07, 'epoch': 0.0}\n",
      "{'loss': 5.4477, 'grad_norm': 3.7178237438201904, 'learning_rate': 8.88888888888889e-07, 'epoch': 0.0}\n",
      "{'loss': 5.7587, 'grad_norm': 3.86826229095459, 'learning_rate': 8.14814814814815e-07, 'epoch': 0.0}\n",
      "{'loss': 5.9845, 'grad_norm': 3.3556106090545654, 'learning_rate': 7.407407407407407e-07, 'epoch': 0.0}\n",
      "{'loss': 5.593, 'grad_norm': 3.1089587211608887, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.0}\n",
      "{'loss': 5.9652, 'grad_norm': 3.935248613357544, 'learning_rate': 5.925925925925927e-07, 'epoch': 0.0}\n",
      "{'loss': 5.6866, 'grad_norm': 2.707876205444336, 'learning_rate': 5.185185185185186e-07, 'epoch': 0.0}\n",
      "{'loss': 6.0409, 'grad_norm': 3.879394292831421, 'learning_rate': 4.444444444444445e-07, 'epoch': 0.0}\n",
      "{'loss': 5.8986, 'grad_norm': 4.214433670043945, 'learning_rate': 3.7037037037037036e-07, 'epoch': 0.0}\n",
      "{'loss': 5.8893, 'grad_norm': 3.366825819015503, 'learning_rate': 2.9629629629629634e-07, 'epoch': 0.0}\n",
      "{'loss': 5.6779, 'grad_norm': 3.4596517086029053, 'learning_rate': 2.2222222222222224e-07, 'epoch': 0.0}\n",
      "{'loss': 5.7266, 'grad_norm': 3.619464159011841, 'learning_rate': 1.4814814814814817e-07, 'epoch': 0.0}\n",
      "{'loss': 5.8745, 'grad_norm': 3.2892532348632812, 'learning_rate': 7.407407407407409e-08, 'epoch': 0.0}\n",
      "{'train_runtime': 8123.9842, 'train_samples_per_second': 0.295, 'train_steps_per_second': 0.018, 'train_loss': 7.260268882115682, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▆▅▆▅▄█▅▅▇▇▆▆▆▅▅▅▅▆▅▄▃▄▃▄▃▃▂▃▂▂▂▂▂▃▁▁▁▂▂▂</td></tr><tr><td>train/learning_rate</td><td>▁▃▅███▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▇▇█▄▆▇▆▆▆▅▅▅▄▃▃▃▃▃▃▃▂▂▂▁▃▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>944263365714432.0</td></tr><tr><td>train/epoch</td><td>0.00267</td></tr><tr><td>train/global_step</td><td>150</td></tr><tr><td>train/grad_norm</td><td>3.28925</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>5.8745</td></tr><tr><td>train_loss</td><td>7.26027</td></tr><tr><td>train_runtime</td><td>8123.9842</td></tr><tr><td>train_samples_per_second</td><td>0.295</td></tr><tr><td>train_steps_per_second</td><td>0.018</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-snow-3</strong> at: <a href='https://wandb.ai/mekhyw-insper/Fine-tune%20Gemma-2-2b-it-abliterated%20on%20CookieBaker%20NSFW%20Dataset/runs/5c5f7111' target=\"_blank\">https://wandb.ai/mekhyw-insper/Fine-tune%20Gemma-2-2b-it-abliterated%20on%20CookieBaker%20NSFW%20Dataset/runs/5c5f7111</a><br/> View project at: <a href='https://wandb.ai/mekhyw-insper/Fine-tune%20Gemma-2-2b-it-abliterated%20on%20CookieBaker%20NSFW%20Dataset' target=\"_blank\">https://wandb.ai/mekhyw-insper/Fine-tune%20Gemma-2-2b-it-abliterated%20on%20CookieBaker%20NSFW%20Dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241129_152318-5c5f7111\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project='Fine-tune Llama-3.2-3B-Instruct-abliterated on CookieBaker NSFW Dataset', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")\n",
    "\n",
    "trainer_nsfw.train()\n",
    "trainer_nsfw.model.save_pretrained(\"../models/NSFW/checkpoint-150\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\AppData\\Roaming\\Python\\Python310\\site-packages\\peft\\tuners\\lora\\bnb.py:336: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/NSFW_merged\\\\tokenizer_config.json',\n",
       " '../models/NSFW_merged\\\\special_tokens_map.json',\n",
       " '../models/NSFW_merged\\\\tokenizer.model',\n",
       " '../models/NSFW_merged\\\\added_tokens.json',\n",
       " '../models/NSFW_merged\\\\tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model_nsfw = trainer_nsfw.model.merge_and_unload()\n",
    "merged_model_nsfw.save_pretrained(\"../models/NSFW_merged\")\n",
    "tokenizer.save_pretrained(\"../models/NSFW_merged\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
