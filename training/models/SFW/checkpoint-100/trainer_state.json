{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0007653770223293963,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 7.653770223293962e-06,
      "grad_norm": 5.055233478546143,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 8.303,
      "step": 1
    },
    {
      "epoch": 1.5307540446587925e-05,
      "grad_norm": 4.2177886962890625,
      "learning_rate": 4.000000000000001e-06,
      "loss": 8.2915,
      "step": 2
    },
    {
      "epoch": 2.296131066988189e-05,
      "grad_norm": 4.7495198249816895,
      "learning_rate": 6e-06,
      "loss": 8.5407,
      "step": 3
    },
    {
      "epoch": 3.061508089317585e-05,
      "grad_norm": 4.732071399688721,
      "learning_rate": 8.000000000000001e-06,
      "loss": 8.342,
      "step": 4
    },
    {
      "epoch": 3.826885111646981e-05,
      "grad_norm": NaN,
      "learning_rate": 8.000000000000001e-06,
      "loss": 8.411,
      "step": 5
    },
    {
      "epoch": 4.592262133976378e-05,
      "grad_norm": 5.214311122894287,
      "learning_rate": 1e-05,
      "loss": 9.2133,
      "step": 6
    },
    {
      "epoch": 5.357639156305774e-05,
      "grad_norm": 4.42290735244751,
      "learning_rate": 9.894736842105264e-06,
      "loss": 8.3173,
      "step": 7
    },
    {
      "epoch": 6.12301617863517e-05,
      "grad_norm": 6.658257484436035,
      "learning_rate": 9.789473684210527e-06,
      "loss": 10.3201,
      "step": 8
    },
    {
      "epoch": 6.888393200964566e-05,
      "grad_norm": 5.252752780914307,
      "learning_rate": 9.68421052631579e-06,
      "loss": 8.7428,
      "step": 9
    },
    {
      "epoch": 7.653770223293962e-05,
      "grad_norm": 5.69586706161499,
      "learning_rate": 9.578947368421054e-06,
      "loss": 9.4293,
      "step": 10
    },
    {
      "epoch": 8.41914724562336e-05,
      "grad_norm": 5.565417766571045,
      "learning_rate": 9.473684210526315e-06,
      "loss": 9.2592,
      "step": 11
    },
    {
      "epoch": 9.184524267952755e-05,
      "grad_norm": 5.478926658630371,
      "learning_rate": 9.36842105263158e-06,
      "loss": 9.0882,
      "step": 12
    },
    {
      "epoch": 9.949901290282152e-05,
      "grad_norm": 5.838810443878174,
      "learning_rate": 9.263157894736842e-06,
      "loss": 9.1981,
      "step": 13
    },
    {
      "epoch": 0.00010715278312611548,
      "grad_norm": 6.73486328125,
      "learning_rate": 9.157894736842105e-06,
      "loss": 9.8557,
      "step": 14
    },
    {
      "epoch": 0.00011480655334940944,
      "grad_norm": 6.073154449462891,
      "learning_rate": 9.05263157894737e-06,
      "loss": 9.5539,
      "step": 15
    },
    {
      "epoch": 0.0001224603235727034,
      "grad_norm": 5.735259532928467,
      "learning_rate": 8.947368421052632e-06,
      "loss": 8.4214,
      "step": 16
    },
    {
      "epoch": 0.00013011409379599736,
      "grad_norm": 3.3340885639190674,
      "learning_rate": 8.842105263157895e-06,
      "loss": 6.5836,
      "step": 17
    },
    {
      "epoch": 0.00013776786401929132,
      "grad_norm": 5.548854351043701,
      "learning_rate": 8.736842105263158e-06,
      "loss": 8.475,
      "step": 18
    },
    {
      "epoch": 0.00014542163424258528,
      "grad_norm": 4.757812976837158,
      "learning_rate": 8.631578947368422e-06,
      "loss": 8.0636,
      "step": 19
    },
    {
      "epoch": 0.00015307540446587924,
      "grad_norm": 4.399514198303223,
      "learning_rate": 8.526315789473685e-06,
      "loss": 7.2072,
      "step": 20
    },
    {
      "epoch": 0.00016072917468917323,
      "grad_norm": 5.158522605895996,
      "learning_rate": 8.421052631578948e-06,
      "loss": 7.9704,
      "step": 21
    },
    {
      "epoch": 0.0001683829449124672,
      "grad_norm": 6.7515645027160645,
      "learning_rate": 8.315789473684212e-06,
      "loss": 9.1238,
      "step": 22
    },
    {
      "epoch": 0.00017603671513576115,
      "grad_norm": 4.841698169708252,
      "learning_rate": 8.210526315789475e-06,
      "loss": 7.7554,
      "step": 23
    },
    {
      "epoch": 0.0001836904853590551,
      "grad_norm": 3.833142042160034,
      "learning_rate": 8.105263157894736e-06,
      "loss": 6.4513,
      "step": 24
    },
    {
      "epoch": 0.00019134425558234907,
      "grad_norm": 6.785885334014893,
      "learning_rate": 8.000000000000001e-06,
      "loss": 9.3028,
      "step": 25
    },
    {
      "epoch": 0.00019899802580564303,
      "grad_norm": 5.293527603149414,
      "learning_rate": 7.894736842105265e-06,
      "loss": 8.0192,
      "step": 26
    },
    {
      "epoch": 0.000206651796028937,
      "grad_norm": 6.94694185256958,
      "learning_rate": 7.789473684210526e-06,
      "loss": 9.044,
      "step": 27
    },
    {
      "epoch": 0.00021430556625223095,
      "grad_norm": 5.266158580780029,
      "learning_rate": 7.68421052631579e-06,
      "loss": 7.4325,
      "step": 28
    },
    {
      "epoch": 0.0002219593364755249,
      "grad_norm": 5.405332565307617,
      "learning_rate": 7.578947368421054e-06,
      "loss": 7.7283,
      "step": 29
    },
    {
      "epoch": 0.00022961310669881887,
      "grad_norm": 5.888077259063721,
      "learning_rate": 7.473684210526316e-06,
      "loss": 8.5541,
      "step": 30
    },
    {
      "epoch": 0.00023726687692211283,
      "grad_norm": 5.320357322692871,
      "learning_rate": 7.368421052631579e-06,
      "loss": 7.8034,
      "step": 31
    },
    {
      "epoch": 0.0002449206471454068,
      "grad_norm": 4.718094825744629,
      "learning_rate": 7.263157894736843e-06,
      "loss": 7.0444,
      "step": 32
    },
    {
      "epoch": 0.0002525744173687008,
      "grad_norm": 4.410869121551514,
      "learning_rate": 7.157894736842106e-06,
      "loss": 7.2842,
      "step": 33
    },
    {
      "epoch": 0.0002602281875919947,
      "grad_norm": 5.286590576171875,
      "learning_rate": 7.052631578947369e-06,
      "loss": 7.6233,
      "step": 34
    },
    {
      "epoch": 0.0002678819578152887,
      "grad_norm": 6.1251139640808105,
      "learning_rate": 6.947368421052632e-06,
      "loss": 8.1956,
      "step": 35
    },
    {
      "epoch": 0.00027553572803858264,
      "grad_norm": 6.085124969482422,
      "learning_rate": 6.842105263157896e-06,
      "loss": 8.0323,
      "step": 36
    },
    {
      "epoch": 0.0002831894982618766,
      "grad_norm": 5.802402496337891,
      "learning_rate": 6.736842105263158e-06,
      "loss": 8.0321,
      "step": 37
    },
    {
      "epoch": 0.00029084326848517056,
      "grad_norm": 6.876945972442627,
      "learning_rate": 6.631578947368421e-06,
      "loss": 8.636,
      "step": 38
    },
    {
      "epoch": 0.00029849703870846455,
      "grad_norm": 5.892759799957275,
      "learning_rate": 6.526315789473685e-06,
      "loss": 7.7,
      "step": 39
    },
    {
      "epoch": 0.0003061508089317585,
      "grad_norm": 5.581000328063965,
      "learning_rate": 6.421052631578948e-06,
      "loss": 7.4925,
      "step": 40
    },
    {
      "epoch": 0.00031380457915505247,
      "grad_norm": 6.049129009246826,
      "learning_rate": 6.31578947368421e-06,
      "loss": 7.9121,
      "step": 41
    },
    {
      "epoch": 0.00032145834937834646,
      "grad_norm": 6.650177955627441,
      "learning_rate": 6.2105263157894745e-06,
      "loss": 8.109,
      "step": 42
    },
    {
      "epoch": 0.0003291121196016404,
      "grad_norm": 5.1621270179748535,
      "learning_rate": 6.105263157894738e-06,
      "loss": 7.1006,
      "step": 43
    },
    {
      "epoch": 0.0003367658898249344,
      "grad_norm": 5.522348403930664,
      "learning_rate": 6e-06,
      "loss": 7.3031,
      "step": 44
    },
    {
      "epoch": 0.0003444196600482283,
      "grad_norm": 6.008897304534912,
      "learning_rate": 5.8947368421052634e-06,
      "loss": 7.8467,
      "step": 45
    },
    {
      "epoch": 0.0003520734302715223,
      "grad_norm": 6.129851818084717,
      "learning_rate": 5.789473684210527e-06,
      "loss": 7.378,
      "step": 46
    },
    {
      "epoch": 0.00035972720049481623,
      "grad_norm": 5.204965114593506,
      "learning_rate": 5.68421052631579e-06,
      "loss": 7.0651,
      "step": 47
    },
    {
      "epoch": 0.0003673809707181102,
      "grad_norm": 5.873230457305908,
      "learning_rate": 5.578947368421052e-06,
      "loss": 7.4117,
      "step": 48
    },
    {
      "epoch": 0.00037503474094140415,
      "grad_norm": 6.7435712814331055,
      "learning_rate": 5.4736842105263165e-06,
      "loss": 7.9799,
      "step": 49
    },
    {
      "epoch": 0.00038268851116469814,
      "grad_norm": 5.534829139709473,
      "learning_rate": 5.36842105263158e-06,
      "loss": 7.1706,
      "step": 50
    },
    {
      "epoch": 0.0003903422813879921,
      "grad_norm": 5.784252643585205,
      "learning_rate": 5.263157894736842e-06,
      "loss": 7.2383,
      "step": 51
    },
    {
      "epoch": 0.00039799605161128606,
      "grad_norm": 6.506998538970947,
      "learning_rate": 5.157894736842106e-06,
      "loss": 7.3285,
      "step": 52
    },
    {
      "epoch": 0.00040564982183458,
      "grad_norm": 5.981656074523926,
      "learning_rate": 5.052631578947369e-06,
      "loss": 7.4998,
      "step": 53
    },
    {
      "epoch": 0.000413303592057874,
      "grad_norm": NaN,
      "learning_rate": 5.052631578947369e-06,
      "loss": 7.5363,
      "step": 54
    },
    {
      "epoch": 0.00042095736228116797,
      "grad_norm": 5.821463108062744,
      "learning_rate": 4.947368421052632e-06,
      "loss": 7.2232,
      "step": 55
    },
    {
      "epoch": 0.0004286111325044619,
      "grad_norm": 6.124855041503906,
      "learning_rate": 4.842105263157895e-06,
      "loss": 7.2126,
      "step": 56
    },
    {
      "epoch": 0.0004362649027277559,
      "grad_norm": 6.408603668212891,
      "learning_rate": 4.736842105263158e-06,
      "loss": 7.4917,
      "step": 57
    },
    {
      "epoch": 0.0004439186729510498,
      "grad_norm": 6.3508195877075195,
      "learning_rate": 4.631578947368421e-06,
      "loss": 7.6221,
      "step": 58
    },
    {
      "epoch": 0.0004515724431743438,
      "grad_norm": 4.868586540222168,
      "learning_rate": 4.526315789473685e-06,
      "loss": 6.9212,
      "step": 59
    },
    {
      "epoch": 0.00045922621339763775,
      "grad_norm": 4.98696756362915,
      "learning_rate": 4.4210526315789476e-06,
      "loss": 6.7319,
      "step": 60
    },
    {
      "epoch": 0.00046687998362093173,
      "grad_norm": 5.348174095153809,
      "learning_rate": 4.315789473684211e-06,
      "loss": 6.8074,
      "step": 61
    },
    {
      "epoch": 0.00047453375384422567,
      "grad_norm": 5.5963239669799805,
      "learning_rate": 4.210526315789474e-06,
      "loss": 6.8548,
      "step": 62
    },
    {
      "epoch": 0.00048218752406751966,
      "grad_norm": 5.042436599731445,
      "learning_rate": 4.105263157894737e-06,
      "loss": 6.5045,
      "step": 63
    },
    {
      "epoch": 0.0004898412942908136,
      "grad_norm": 6.2903900146484375,
      "learning_rate": 4.000000000000001e-06,
      "loss": 7.3873,
      "step": 64
    },
    {
      "epoch": 0.0004974950645141075,
      "grad_norm": 5.934410095214844,
      "learning_rate": 3.894736842105263e-06,
      "loss": 7.1183,
      "step": 65
    },
    {
      "epoch": 0.0005051488347374016,
      "grad_norm": 5.436816692352295,
      "learning_rate": 3.789473684210527e-06,
      "loss": 6.9642,
      "step": 66
    },
    {
      "epoch": 0.0005128026049606955,
      "grad_norm": 6.165295124053955,
      "learning_rate": 3.6842105263157896e-06,
      "loss": 7.1527,
      "step": 67
    },
    {
      "epoch": 0.0005204563751839894,
      "grad_norm": 5.5192766189575195,
      "learning_rate": 3.578947368421053e-06,
      "loss": 6.7868,
      "step": 68
    },
    {
      "epoch": 0.0005281101454072835,
      "grad_norm": 6.611073970794678,
      "learning_rate": 3.473684210526316e-06,
      "loss": 7.2995,
      "step": 69
    },
    {
      "epoch": 0.0005357639156305774,
      "grad_norm": 4.842761039733887,
      "learning_rate": 3.368421052631579e-06,
      "loss": 6.2695,
      "step": 70
    },
    {
      "epoch": 0.0005434176858538713,
      "grad_norm": 6.116581439971924,
      "learning_rate": 3.2631578947368423e-06,
      "loss": 6.9313,
      "step": 71
    },
    {
      "epoch": 0.0005510714560771653,
      "grad_norm": 4.875024318695068,
      "learning_rate": 3.157894736842105e-06,
      "loss": 6.4199,
      "step": 72
    },
    {
      "epoch": 0.0005587252263004593,
      "grad_norm": 5.731195449829102,
      "learning_rate": 3.052631578947369e-06,
      "loss": 6.9286,
      "step": 73
    },
    {
      "epoch": 0.0005663789965237532,
      "grad_norm": 5.896537780761719,
      "learning_rate": 2.9473684210526317e-06,
      "loss": 6.8302,
      "step": 74
    },
    {
      "epoch": 0.0005740327667470472,
      "grad_norm": 5.21926736831665,
      "learning_rate": 2.842105263157895e-06,
      "loss": 6.6685,
      "step": 75
    },
    {
      "epoch": 0.0005816865369703411,
      "grad_norm": 5.969410419464111,
      "learning_rate": 2.7368421052631583e-06,
      "loss": 6.9847,
      "step": 76
    },
    {
      "epoch": 0.0005893403071936352,
      "grad_norm": 4.825680255889893,
      "learning_rate": 2.631578947368421e-06,
      "loss": 6.4351,
      "step": 77
    },
    {
      "epoch": 0.0005969940774169291,
      "grad_norm": 6.216092586517334,
      "learning_rate": 2.5263157894736844e-06,
      "loss": 7.1392,
      "step": 78
    },
    {
      "epoch": 0.000604647847640223,
      "grad_norm": 5.5854949951171875,
      "learning_rate": 2.4210526315789477e-06,
      "loss": 7.0475,
      "step": 79
    },
    {
      "epoch": 0.000612301617863517,
      "grad_norm": 6.3486809730529785,
      "learning_rate": 2.3157894736842105e-06,
      "loss": 7.0272,
      "step": 80
    },
    {
      "epoch": 0.000619955388086811,
      "grad_norm": 4.5949907302856445,
      "learning_rate": 2.2105263157894738e-06,
      "loss": 6.6095,
      "step": 81
    },
    {
      "epoch": 0.0006276091583101049,
      "grad_norm": 4.425053596496582,
      "learning_rate": 2.105263157894737e-06,
      "loss": 6.215,
      "step": 82
    },
    {
      "epoch": 0.0006352629285333989,
      "grad_norm": 5.238925933837891,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 6.8899,
      "step": 83
    },
    {
      "epoch": 0.0006429166987566929,
      "grad_norm": 5.014461517333984,
      "learning_rate": 1.8947368421052634e-06,
      "loss": 6.3965,
      "step": 84
    },
    {
      "epoch": 0.0006505704689799868,
      "grad_norm": 3.3814477920532227,
      "learning_rate": 1.7894736842105265e-06,
      "loss": 5.0833,
      "step": 85
    },
    {
      "epoch": 0.0006582242392032808,
      "grad_norm": 4.633682727813721,
      "learning_rate": 1.6842105263157895e-06,
      "loss": 6.3131,
      "step": 86
    },
    {
      "epoch": 0.0006658780094265747,
      "grad_norm": 5.365000247955322,
      "learning_rate": 1.5789473684210526e-06,
      "loss": 6.5485,
      "step": 87
    },
    {
      "epoch": 0.0006735317796498688,
      "grad_norm": 4.211307525634766,
      "learning_rate": 1.4736842105263159e-06,
      "loss": 5.9397,
      "step": 88
    },
    {
      "epoch": 0.0006811855498731627,
      "grad_norm": 5.271914005279541,
      "learning_rate": 1.3684210526315791e-06,
      "loss": 6.4911,
      "step": 89
    },
    {
      "epoch": 0.0006888393200964566,
      "grad_norm": 4.301763534545898,
      "learning_rate": 1.2631578947368422e-06,
      "loss": 5.8426,
      "step": 90
    },
    {
      "epoch": 0.0006964930903197506,
      "grad_norm": 4.9831223487854,
      "learning_rate": 1.1578947368421053e-06,
      "loss": 6.1382,
      "step": 91
    },
    {
      "epoch": 0.0007041468605430446,
      "grad_norm": 4.7019453048706055,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 6.4363,
      "step": 92
    },
    {
      "epoch": 0.0007118006307663385,
      "grad_norm": 5.328712463378906,
      "learning_rate": 9.473684210526317e-07,
      "loss": 6.5492,
      "step": 93
    },
    {
      "epoch": 0.0007194544009896325,
      "grad_norm": 5.583320140838623,
      "learning_rate": 8.421052631578948e-07,
      "loss": 6.7004,
      "step": 94
    },
    {
      "epoch": 0.0007271081712129265,
      "grad_norm": 5.0626373291015625,
      "learning_rate": 7.368421052631579e-07,
      "loss": 6.5739,
      "step": 95
    },
    {
      "epoch": 0.0007347619414362204,
      "grad_norm": 4.52918004989624,
      "learning_rate": 6.315789473684211e-07,
      "loss": 6.5407,
      "step": 96
    },
    {
      "epoch": 0.0007424157116595144,
      "grad_norm": 5.5578293800354,
      "learning_rate": 5.263157894736843e-07,
      "loss": 6.8999,
      "step": 97
    },
    {
      "epoch": 0.0007500694818828083,
      "grad_norm": 4.365411281585693,
      "learning_rate": 4.210526315789474e-07,
      "loss": 5.9772,
      "step": 98
    },
    {
      "epoch": 0.0007577232521061023,
      "grad_norm": 4.845185279846191,
      "learning_rate": 3.1578947368421055e-07,
      "loss": 6.3982,
      "step": 99
    },
    {
      "epoch": 0.0007653770223293963,
      "grad_norm": 5.385493755340576,
      "learning_rate": 2.105263157894737e-07,
      "loss": 6.8065,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 764821703863296.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
